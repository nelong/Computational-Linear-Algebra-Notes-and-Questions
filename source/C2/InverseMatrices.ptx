<section xml:id="InverseMatrices">
  <title>Inverse Matrices</title>
<introduction>
  <p>
    In this section, we will only consider square matrices.
  </p>
  <definition>
    <p>
      A matrix <m>A \in M_{n \times n}</m> is <term>invertible</term> if there exists a matrix <m>B</m> such that <m>AB=Id_n</m> and <m>BA=Id_n</m>. The inverse matrix of <m>A</m> is denoted <m>A^{-1}</m>.
    </p>
  </definition>
  <p>
    Be careful that you do not use the notation <m>A^{-1}</m> until you have shown that <m>A</m> is invertible. By inverse, we mean the multiplicative inverse for a matrix. A matrix that is not invertible is called a <term>singular matrix</term>. A <term>non-singular matrix</term> is an invertible matrix.
  </p>
  <p>
    In the next couple of sections we will examine the following two questions:
    <ul>
      <li>How can you efficently calculate the inverse matrix for a given <m>A</m>?</li>
      <li>How can you determine when a matrix is invertible without finding its inverse?</li>
    </ul>
  </p>
</introduction>
<subsection>
  <title>Computing Inverses</title>

<investigation>
  <introduction>
    <p>
      We will look at a way to find the inverse matrix of <m>A</m> in terms of the matrix-vector product and how that can be used as a representation of matrix multiplication.
    </p>
  </introduction>
  <task>
    <p>
      We want to find a matrix <m>C</m> such that <m>AC=Id</m>. So let's expand <m>C</m> as columns.
      <me>AC=A [\vec{c}_1 \; \vec{c}_2 \; \ldots \; \vec{c}_n]=[A\vec{c}_1 \; A\vec{c}_2 \; \ldots \; A\vec{c}_n]</me>
      Using this perspective on the equation <m>AC=Id</m>, we get
      <me>A\vec{c}_1=\colvec{1 \\ 0\\0\\\vdots\\0}, \; A\vec{c}_2=\colvec{0 \\ 1\\0\\\vdots\\0}, \: \cdots, \; A\vec{c}_n=\colvec{0 \\ 0\\0\\\vdots\\1}</me>
      How would we find out if there were any solutions to these matrix equations?
    </p>
  </task>
  <task>
    <p>
      How could you find solutions to all of these matrix equations all at once?
    </p>
  </task>
</investigation>


<p>
  In general computing the inverse of a matrix takes more time and operations than solving a system of equations. For this reason, it is generally easier to find and solve a related system of equations problem than to compute the inverse matrix. We will outline a few ways to find inverse matrices and compute a few small examples.
</p>

<investigation><statement><p> If a matrix <m>A</m> is row reduced to
<m>Id_n</m> by elementary row operations corresponding (in order of
use) to elementary matrices <m>E_1</m>, <m>E_2</m>, ... , <m>E_k</m>,
give an expression for <m>A^{-1}</m>.
</p></statement></investigation>

<investigation><statement><p> Use your answer to the previous question to prove the following:

Any sequence of elementary row operations that reduces <m>A</m> to <m>Id_n</m> also transforms <m>Id_n</m> into <m>A^{-1}</m>.
</p></statement></investigation>

<p>The previous result shows that computing inverses is equivalent to a row reduction problem. In particular, if <m>A</m> is invertible, then reducing <m>[ A \quad | \quad Id_n]</m> to reduced row echelon form will produce the matrix <m>[ Id_n \quad | \quad A^{-1}]</m>.</p>

<investigation xml:id="inv22"><statement><p>Use the idea above to compute the inverse of <m>\begin{bmatrix} a\amp b\\c\amp d \end{bmatrix}</m>. Be sure to note any assumptions you will need to make in order to reduce <m>[ A \quad | \quad Id_n]</m> to <m>[ Id_n \quad | \quad A^{-1}]</m>.
</p></statement></investigation>

<exercise><statement><p> If <m>A=\begin{bmatrix}1\amp  0\amp  1 \\0\amp 2\amp -1 \\ 0\amp 6\amp -1\end{bmatrix}</m>, find <m>A^{-1}</m> and check that <m>A A^{-1}=Id_3</m>.
</p></statement></exercise>

<exercise><introduction><p>
If <m>A=\begin{bmatrix} 0\amp -1\\3\amp 4 \end{bmatrix}</m>, find
<m>A^{-1}</m> and use your answer to solve <m>A\vec{x} = \vec{b}</m>
if:</p></introduction>
<task><p><m>\vec{b} =\colvec{3\\ 1}</m></p></task>
<task><p><m>\vec{b} =\colvec{-1\\ -2}</m></p></task>
<task><p><m>\vec{b} =\colvec{0\\ 5}</m></p></task>
<task><p><m>\vec{b} =\colvec{\alpha\\ \beta}</m></p></task>
</exercise>
</subsection>
<subsection>
  <title>Elementary Matrices</title>
<p>
  Recall that an elementary row operation on a matrix is an operation of the form:
  <ul>
    <li>multiplying a row by a non-zero scalar</li>
    <li>switching two rows</li>
    <li>adding a multiple of one row to another row</li>
  </ul>
  Elementary matrices are obtained by performing an elementary operation on the identity matrix.
</p>
<investigation>
  <introduction>
    <p>
      Give the elementary matrix obtained by performing the given operation on <m>Id_3</m>. (These are 4 separate questions):
    </p>
  </introduction>
  <task>
    <p>
      Scaling the first row by <m>\alpha</m>
    </p>
  </task>
  <task>
    <p>
      Switching the second and third rows
    </p>
  </task>
  <task>
    <p>
      Adding 3 times the 2nd row to the 1st row
    </p>
  </task>
  <task>
    <p>
      Adding 3 times the 1st row to the 2nd row
    </p>
  </task>
</investigation>

<investigation>
  <statement>
    <p>
      Check that your answer to the previous question does the desired operation by multiplying each of the four previous elementary matrices by <m>\begin{bmatrix} a\amp b\amp c\\d\amp e\amp f\\g\amp h\amp i \end{bmatrix}</m>. Which side do you multiply the elementary matrix on to correspond to row operations?
    </p>
  </statement>
</investigation>

<investigation>
  <statement>
    <p>
      Compute (and verify) the inverse of each of the elementary matrices from the previous problems.
    </p>
  </statement>
  <hint><p>Think about how you would go backwards for each of the elementary operations.</p></hint>
</investigation>

<p>
  Your work on the previous questions should convince you that elementary matrices are invertible and that multiplying by an elementary matrix produces the same result as having performed the corresponding elementary row operation. Elementary matrices offer a way of keeping track of elementary operations. We will not write our a proof of the following theorem at this time, but we state it for future uses:
</p>

<theorem>
<statement>
  <p>
Elementary matrices are invertible and the inverse matrix is an
elementary matrix corresponding to the inverse elementary operation.
  </p>
</statement>
</theorem>

<p>You shoud, however, at this time prove the theorems below.</p>
<theorem>
  <statement>
    <p>
      If <m>A</m> and <m>B</m> are invertible <m>n</m> by <m>n</m>
      matrices, then <m>(AB)^{-1} =B^{-1}A^{-1}</m> and <m>AB</m> is
      an invertible <m>n</m> by <m>n</m> matrix.
    </p>
  </statement>
</theorem>

<theorem xml:id="q11"><statement><p>If <m>A</m> can be reduced to <m>Id_n</m> by elementary row operations, then <m>A</m> is invertible.
</p></statement></theorem>

<investigation><statement><p> Give all values of <m>k</m> where <m>A=\begin{bmatrix} 1\amp 0\amp 2\\-1\amp k\amp 4\\3\amp 5\amp 1 \end{bmatrix}</m> will be invertible.
</p></statement></investigation>

<investigation><statement><p> Give all values of <m>k</m> where <m>A=\begin{bmatrix} 1\amp 0\amp 2\\-1\amp k\amp 4\\3\amp -1\amp 1 \end{bmatrix}</m> will be invertible.
</p></statement></investigation>

<investigation><statement><p> How many pivots must a matrix <m>A</m> have in order to be row reducible to <m>Id_n</m>? Justify using previous results.
</p></statement></investigation>

<theorem><statement><p>If <m>A</m> is invertible, then <m>A\vec{x}
=\vec{b}</m> has a unique solution for every <m>\vec{b} \in
\mathbb{R}^n</m>.  </p></statement></theorem>

<investigation><statement><p> Prove or disprove: If <m>A</m> and <m>B</m> are invertible <m>n</m> by <m>n</m> matrices, then <m>A+B</m> is invertible.
</p></statement></investigation>

<investigation><statement><p> Prove that if <m>A</m> is invertible, then <m>A^T</m> is invertible.
</p></statement></investigation>
</subsection>
</section>


